{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import itertools\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.base import TransformerMixin\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "from collections import Counter\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from polyglot import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_code(directory, lang):\n",
    "    text = []\n",
    "    files = glob.glob('benchmarks/benchmarksgame/bench/{}/*{}'.format(directory, lang))    \n",
    "    for file in files:\n",
    "        with open(file,) as f:\n",
    "            text.append((f.read(), lang))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "languages = ['.gcc', 'csharp', '.sbcl',\n",
    "             '.clojure', '.ats', '.dart',\n",
    "             '.erlang', '.fpascal', '.fsharp',\n",
    "            '.gnat', '.go', '.gpp', '.hack', '.hs'\n",
    "            '.ifc', '.java', '.javascript',\n",
    "            '.jruby', '.ocaml', '.oz', '.perl',\n",
    "            '.php', '.python3', '.racket', '.rust',\n",
    "            '.scala', '.vw', '.yarv']\n",
    "\n",
    "all_langs = [read_code('fasta', lang) for lang in languages]\n",
    "all_langs  = list(itertools.chain(*all_langs))\n",
    "langs = [x[0] for x in all_langs]\n",
    "exts = [x[1] for x in all_langs]\n",
    "\n",
    "all_langs_fr = [read_code('fastaredux', lang) for lang in languages]\n",
    "all_langs_fr  = list(itertools.chain(*all_langs_fr))\n",
    "langs_fr = [x[0] for x in all_langs_fr]\n",
    "exts_fr = [x[1] for x in all_langs_fr]\n",
    "\n",
    "all_langs_b = [read_code('binarytrees', lang) for lang in languages]\n",
    "all_langs_b  = list(itertools.chain(*all_langs_b))\n",
    "langs_b = [x[0] for x in all_langs_b]\n",
    "exts_b = [x[1] for x in all_langs_b]\n",
    "\n",
    "all_langs_m = [read_code('meteor', lang) for lang in languages]\n",
    "all_langs_m  = list(itertools.chain(*all_langs_m))\n",
    "langs_m = [x[0] for x in all_langs_m]\n",
    "exts_m = [x[1] for x in all_langs_m]\n",
    "\n",
    "x_train = langs+langs_fr+langs_b+langs_m\n",
    "y_train = exts+exts_fr+exts_b+exts_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_test():\n",
    "    text = []\n",
    "    for file in range(32):\n",
    "        with open('test/{}'.format(file+1)) as f:\n",
    "            text.append((f.read(), file+1))\n",
    "    return text\n",
    "\n",
    "ans = pd.read_csv('test.csv', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "repl_ans = ans.replace({'clojure':'.clojure', 'python':'.python3',\n",
    "                       'javascript':'.javascript', 'ruby':'.jruby',\n",
    "                       'haskell':'.hs', 'scheme':'.scm', 'java':'.java',\n",
    "                       'scala':'.scala', 'tcl':'.tcl', 'php':'.php',\n",
    "                       'ocaml':'.ocaml'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_test = [x[0] for x in get_test()]\n",
    "y_test = list(repl_ans[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FunctionFeaturizer(TransformerMixin):\n",
    "    def __init__(self, *featurizers):\n",
    "        self.featurizers = featurizers\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        '''All SciKit-learn compatible transformers and classifiers have the same\n",
    "        interface. `fit` should always return the same object (self)'''\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        '''Given a list of original data, return a list of feature vectors'''\n",
    "        feature_vectors = []\n",
    "        for x in X:\n",
    "            feature_vector = [f(x) for f in self.featurizers]\n",
    "            feature_vectors.append(feature_vector)\n",
    "        \n",
    "        return np.array(feature_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BagOfWordsFeaturizer(TransformerMixin):\n",
    "    def __init__(self, num_words=None):\n",
    "        self.num_words = num_words\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        words = []\n",
    "        for x in X:\n",
    "            x = TextBlob(x.lower())\n",
    "            words += [word.lemmatize() for word in x.words]\n",
    "        if self.num_words:\n",
    "            words = Counter(words)\n",
    "            self._vocab = [word for word, _ in words.most_common(self.num_words)]\n",
    "        else:\n",
    "            self._vocab = list(set(words))\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        vectors = []\n",
    "        for x in X:\n",
    "            x = TextBlob(x.lower())\n",
    "            word_count = Counter(x.words)\n",
    "            vector = [0] * len(self._vocab)\n",
    "            for word, count in word_count.items():\n",
    "                try:\n",
    "                    idx = self._vocab.index(word)\n",
    "                    vector[idx] = count\n",
    "                except ValueError:\n",
    "                    pass\n",
    "            vectors.append(vector)\n",
    "        return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def percentage_of_parens(text):\n",
    "    total_length = len(text)\n",
    "    text = re.sub(r'[^()]', '', text)\n",
    "    punc_length = len(text)\n",
    "    \n",
    "    return punc_length / total_length\n",
    "\n",
    "f = FunctionFeaturizer(percentage_of_parens,\n",
    "                      percentage_of_bracks,\n",
    "                      percentage_of_semi,\n",
    "                      percentage_of_dollar,\n",
    "                      percentage_of_hyphen,\n",
    "                      percentage_of_arrow,\n",
    "                      presence_of_end,\n",
    "                      presence_of_def,\n",
    "                      presence_of_elif,\n",
    "                      presence_of_elsif,\n",
    "                      presence_of_return,\n",
    "                      presence_of_defun,\n",
    "                      presence_of_object,\n",
    "                      #presence_of_public,\n",
    "                      presence_of_func,\n",
    "                      presence_of_fun,\n",
    "                      presence_of_static,\n",
    "                      #percentage_of_ast,\n",
    "                      presence_of_struct,\n",
    "                      presence_of_let,\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "code_featurizer = make_union(\n",
    "    BagOfWordsFeaturizer(50),\n",
    "    f\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 're' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2189-bcb29af5120c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpipe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/apierce/dev/TIY/projects/polyglot/.direnv/python-3.4.3/lib/python3.4/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0mthe\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \"\"\"\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pre_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/apierce/dev/TIY/projects/polyglot/.direnv/python-3.4.3/lib/python3.4/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_pre_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fit_transform\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m                 \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m                 \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/apierce/dev/TIY/projects/polyglot/.direnv/python-3.4.3/lib/python3.4/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2185-07addcb3945b>\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mfeature_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mfeature_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeaturizers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mfeature_vectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2185-07addcb3945b>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mfeature_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mfeature_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeaturizers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mfeature_vectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/apierce/dev/TIY/projects/polyglot/polyglot.py\u001b[0m in \u001b[0;36mpercentage_of_bracks\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mpercentage_of_bracks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtotal_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'[^[]]'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 're' is not defined"
     ]
    }
   ],
   "source": [
    "pipe = make_pipeline(f, DecisionTreeClassifier())\n",
    "pipe.fit(x_train, y_train)\n",
    "pipe.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pipe.fit(x_test, y_test)\n",
    "#pipe.score(x_test, y_test)\n",
    "#vectorizer = CountVectorizer()\n",
    "#pipe1 = make_pipeline(code_featurizer, MultinomialNB())\n",
    "#pipe1.fit(x_train, y_train)\n",
    "#pipe1.score(x_train, y_train)\n",
    "#vectorizer.fit(x_train, y_train)\n",
    "#vectorizer.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "random_tree = make_pipeline(f, RandomForestClassifier())\n",
    "\n",
    "random_tree.fit(x_train, y_train)\n",
    "random_tree.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#x_train = vectorizer.transform(x_train)\n",
    "#x_test = vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#classifier = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#classifier.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#classifier.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(classification_report(random_tree.predict(x_test), y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
