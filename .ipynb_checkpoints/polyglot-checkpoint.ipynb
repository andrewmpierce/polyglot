{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polyglot\n",
    "\n",
    "This Ipython notebook is a showcase of Polyglot. It is a program that attempts to identify a programming language given a code snippet. It uses the sklearn library and custom selectrion criteria to generate the best guess for the given snippet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "import itertools\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.base import TransformerMixin\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "from collections import Counter\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from polyglot_lib import *\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_code(directory, lang):\n",
    "    text = []\n",
    "    files = glob.glob('benchmarks/benchmarksgame/bench/{}/*{}'.format(directory, lang))    \n",
    "    for file in files:\n",
    "        with open(file,) as f:\n",
    "            text.append((f.read(), lang))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "languages = ['.gcc', '.csharp', '.sbcl',\n",
    "             '.clojure', '.ats',\n",
    "            '.go', '.hack', '.hs'\n",
    "            '.java', '.javascript',\n",
    "            '.jruby', '.ocaml', '.perl', '.tcl'\n",
    "            '.php', '.python3', '.racket', '.rust',\n",
    "            '.scala', '.scm', '.vw']\n",
    "\n",
    "all_langs = [read_code('fasta', lang) for lang in languages]\n",
    "all_langs  = list(itertools.chain(*all_langs))\n",
    "langs = [x[0] for x in all_langs]\n",
    "exts = [x[1] for x in all_langs]\n",
    "\n",
    "all_langs_fr = [read_code('fastaredux', lang) for lang in languages]\n",
    "all_langs_fr  = list(itertools.chain(*all_langs_fr))\n",
    "langs_fr = [x[0] for x in all_langs_fr]\n",
    "exts_fr = [x[1] for x in all_langs_fr]\n",
    "\n",
    "all_langs_b = [read_code('binarytrees', lang) for lang in languages]\n",
    "all_langs_b  = list(itertools.chain(*all_langs_b))\n",
    "langs_b = [x[0] for x in all_langs_b]\n",
    "exts_b = [x[1] for x in all_langs_b]\n",
    "\n",
    "all_langs_m = [read_code('meteor', lang) for lang in languages]\n",
    "all_langs_m  = list(itertools.chain(*all_langs_m))\n",
    "langs_m = [x[0] for x in all_langs_m]\n",
    "exts_m = [x[1] for x in all_langs_m]\n",
    "\n",
    "all_langs_n = [read_code('knucleotide', lang) for lang in languages]\n",
    "all_langs_n  = list(itertools.chain(*all_langs_n))\n",
    "langs_n = [x[0] for x in all_langs_n]\n",
    "exts_n = [x[1] for x in all_langs_n]\n",
    "\n",
    "all_langs_r = [read_code('revcomp', lang) for lang in languages]\n",
    "all_langs_r  = list(itertools.chain(*all_langs_r))\n",
    "langs_r = [x[0] for x in all_langs_r]\n",
    "exts_r = [x[1] for x in all_langs_r]\n",
    "\n",
    "all_langs_rd = [read_code('regexdna', lang) for lang in languages]\n",
    "all_langs_rd  = list(itertools.chain(*all_langs_rd))\n",
    "langs_rd = [x[0] for x in all_langs_rd]\n",
    "exts_rd = [x[1] for x in all_langs_rd]\n",
    "\n",
    "all_langs_md = [read_code('mandelbrot', lang) for lang in languages]\n",
    "all_langs_md  = list(itertools.chain(*all_langs_md))\n",
    "langs_md = [x[0] for x in all_langs_md]\n",
    "exts_md = [x[1] for x in all_langs_md]\n",
    "\n",
    "all_langs_s = [read_code('spectralnorm', lang) for lang in languages]\n",
    "all_langs_s  = list(itertools.chain(*all_langs_s))\n",
    "langs_s = [x[0] for x in all_langs_s]\n",
    "exts_s = [x[1] for x in all_langs_s]\n",
    "\n",
    "all_langs_body = [read_code('nbody', lang) for lang in languages]\n",
    "all_langs_body  = list(itertools.chain(*all_langs_body))\n",
    "langs_body = [x[0] for x in all_langs_body]\n",
    "exts_body = [x[1] for x in all_langs_body]\n",
    "\n",
    "\n",
    "all_langs_t = [read_code('threadring', lang) for lang in languages]\n",
    "all_langs_t  = list(itertools.chain(*all_langs_t))\n",
    "langs_t = [x[0] for x in all_langs_t]\n",
    "exts_t = [x[1] for x in all_langs_t]\n",
    "\n",
    "\n",
    "\n",
    "x = langs+langs_fr+langs_b+langs_m+langs_n+langs_r+langs_rd+langs_md+langs_s\n",
    "x = x+langs_body+langs_t\n",
    "y = exts+exts_fr+exts_b+exts_m+exts_n+exts_r+exts_rd+exts_md+exts_s\n",
    "y = y+exts_body+exts_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_test():\n",
    "    text = []\n",
    "    for file in range(32):\n",
    "        with open('test/{}'.format(file+1)) as f:\n",
    "            text.append((f.read(), file+1))\n",
    "    return text\n",
    "\n",
    "ans = pd.read_csv('test.csv', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "repl_ans = ans.replace({'clojure':'.clojure', 'python':'.python3',\n",
    "                       'javascript':'.javascript', 'ruby':'.jruby',\n",
    "                       'haskell':'.hs', 'scheme':'.scm', 'java':'.java',\n",
    "                       'scala':'.scala', 'tcl':'.tcl', 'php':'.php',\n",
    "                       'ocaml':'.ocaml'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_class = [x[0] for x in get_test()]\n",
    "y_class = list(repl_ans[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FunctionFeaturizer(TransformerMixin):\n",
    "    def __init__(self, *featurizers):\n",
    "        self.featurizers = featurizers\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        '''All SciKit-learn compatible transformers and classifiers have the same\n",
    "        interface. `fit` should always return the same object (self)'''\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        '''Given a list of original data, return a list of feature vectors'''\n",
    "        feature_vectors = []\n",
    "        for x in X:\n",
    "            feature_vector = [f(x) for f in self.featurizers]\n",
    "            feature_vectors.append(feature_vector)\n",
    "        \n",
    "        return np.array(feature_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BagOfWordsFeaturizer(TransformerMixin):\n",
    "    def __init__(self, num_words=None):\n",
    "        self.num_words = num_words\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        words = []\n",
    "        for x in X:\n",
    "            x = TextBlob(x.lower())\n",
    "            words += [word.lemmatize() for word in x.words]\n",
    "        if self.num_words:\n",
    "            words = Counter(words)\n",
    "            self._vocab = [word for word, _ in words.most_common(self.num_words)]\n",
    "        else:\n",
    "            self._vocab = list(set(words))\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        vectors = []\n",
    "        for x in X:\n",
    "            x = TextBlob(x.lower())\n",
    "            word_count = Counter(x.words)\n",
    "            vector = [0] * len(self._vocab)\n",
    "            for word, count in word_count.items():\n",
    "                try:\n",
    "                    idx = self._vocab.index(word)\n",
    "                    vector[idx] = count\n",
    "                except ValueError:\n",
    "                    pass\n",
    "            vectors.append(vector)\n",
    "        return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = FunctionFeaturizer(percentage_of_parens,\n",
    "                      percentage_of_bracks,\n",
    "                      percentage_of_semi,\n",
    "                      percentage_of_dollar,\n",
    "                      percentage_of_hyphen,\n",
    "                      percentage_of_arrow,\n",
    "                      presence_of_end,\n",
    "                      presence_of_def,\n",
    "                      presence_of_elif,\n",
    "                      presence_of_elsif,\n",
    "                      presence_of_return,\n",
    "                      presence_of_defun,\n",
    "                      presence_of_object,\n",
    "                      presence_of_public,\n",
    "                      presence_of_func,\n",
    "                      presence_of_fun,\n",
    "                      presence_of_static,\n",
    "                      percentage_of_ast,\n",
    "                      presence_of_struct,\n",
    "                      presence_of_let,\n",
    "                      presence_of_at,\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "code_featurizer = make_union(\n",
    "    BagOfWordsFeaturizer(70),\n",
    "    f\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Our Data\n",
    "\n",
    "At this point we have seperated our data into test and training data and have created selection criteria. We will make a pipeline with a Random Forest classifier, which uses multiple decision trees, and with our custom featurizer. The first score shows our test sample from our intake data, the second is from the test files given. \n",
    "\n",
    "From the results, it is easy to see that while our program is pretty great at working with the test data from our training data, it is not as good when working with outside test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<307x6745 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 38067 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = MultinomialNB()\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(x_train)\n",
    "vectorizer.transform(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95145631067961167"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tree = make_pipeline(code_featurizer, RandomForestClassifier())\n",
    "random_tree.fit(x_train, y_train)\n",
    "random_tree.score(x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tree.score(x_class, y_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       .ats       1.00      1.00      1.00         4\n",
      "   .clojure       1.00      1.00      1.00         8\n",
      "    .csharp       1.00      0.92      0.96        12\n",
      "       .gcc       1.00      0.92      0.96        13\n",
      "        .go       0.88      1.00      0.93         7\n",
      "      .hack       0.90      1.00      0.95         9\n",
      ".javascript       1.00      0.75      0.86         4\n",
      "     .jruby       1.00      0.83      0.91         6\n",
      "     .ocaml       1.00      1.00      1.00         7\n",
      "      .perl       1.00      1.00      1.00         6\n",
      "   .python3       0.86      1.00      0.92         6\n",
      "    .racket       1.00      0.75      0.86         4\n",
      "      .rust       0.50      1.00      0.67         1\n",
      "      .sbcl       1.00      1.00      1.00         4\n",
      "     .scala       1.00      1.00      1.00        10\n",
      "       .scm       0.00      0.00      0.00         0\n",
      "        .vw       1.00      1.00      1.00         2\n",
      "\n",
      "avg / total       0.97      0.95      0.96       103\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apierce/dev/TIY/projects/polyglot/.direnv/python-3.4.3/lib/python3.4/site-packages/sklearn/metrics/classification.py:960: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(random_tree.predict(x_test), y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   .clojure       1.00      0.67      0.80         6\n",
      "        .go       0.00      0.00      0.00         2\n",
      "      .hack       0.00      0.00      0.00         4\n",
      "        .hs       0.00      0.00      0.00         0\n",
      "      .java       0.00      0.00      0.00         0\n",
      ".javascript       0.50      1.00      0.67         2\n",
      "     .jruby       1.00      0.43      0.60         7\n",
      "     .ocaml       0.50      1.00      0.67         1\n",
      "      .perl       0.00      0.00      0.00         3\n",
      "       .php       0.00      0.00      0.00         0\n",
      "   .python3       0.50      1.00      0.67         2\n",
      "     .scala       1.00      0.67      0.80         3\n",
      "       .scm       0.67      1.00      0.80         2\n",
      "       .tcl       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.62      0.50      0.51        32\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apierce/dev/TIY/projects/polyglot/.direnv/python-3.4.3/lib/python3.4/site-packages/sklearn/metrics/classification.py:958: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/apierce/dev/TIY/projects/polyglot/.direnv/python-3.4.3/lib/python3.4/site-packages/sklearn/metrics/classification.py:960: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(random_tree.predict(x_class), y_class))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "python = '''class BagOfWordsFeaturizer(TransformerMixin):,\n",
    "    def __init__(self, num_words=None):\n",
    "        self.num_words = num_words\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        words = []\n",
    "        for x in X:\n",
    "            x = TextBlob(x.lower())\n",
    "            words += [word.lemmatize() for word in x.words]\n",
    "        if self.num_words:\n",
    "            words = Counter(words)\n",
    "            self._vocab = [word for word, _ in words.most_common(self.num_words)]\n",
    "        else:\n",
    "            self._vocab = list(set(words))\n",
    "        return self'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_lang(text):\n",
    "    ans = random_tree.predict([text])\n",
    "    print(\"Your language is probably {}.\".format(ans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your language is probably ['.python3'].\n"
     ]
    }
   ],
   "source": [
    "get_lang(python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
